---
apiVersion: batch/v1
kind: Job
metadata:
  name: start-date-job
spec:
  template:
    spec:
      containers:
        - name: start-date-job
          image: oci.stackable.tech/sdp/tools:1.0.0-stackable0.0.0-dev
          # N.B. it is possible for the scheduler to report that a DAG exists, only for the worker task to fail if a pod is unexpectedly
          # restarted. Additionally, the db-init job takes a few minutes to complete before the cluster is deployed. The wait/watch steps
          # below are not "water-tight" but add a layer of stability by at least ensuring that the db is initialized and ready and that
          # all pods are reachable (albeit independent of each other).
          command: [
              "bash",
              "-c",
              '
              kubectl rollout status --watch statefulset/airflow-webserver-default
              && kubectl rollout status --watch statefulset/airflow-scheduler-default
              && export AIRFLOW_ADMIN_PASSWORD=$(cat /airflow-credentials/adminUser.password)
              && export ACCESS_TOKEN=$(curl -XPOST http://airflow-webserver-default-headless:8080/auth/token -H ''Content-Type: application/json'' -d ''{"username": "admin", "password": "''$AIRFLOW_ADMIN_PASSWORD''"}'' | jq ''.access_token'' | tr -d ''"'')
              && curl -H "Authorization: Bearer $ACCESS_TOKEN" -H ''Content-Type: application/json'' -XPATCH http://airflow-webserver-default-headless:8080/api/v2/dags/date_demo -d ''{"is_paused": false}'' | jq
              && curl -H "Authorization: Bearer $ACCESS_TOKEN" -H ''Content-Type: application/json'' -XPOST http://airflow-webserver-default-headless:8080/api/v2/dags/date_demo/dagRuns -d ''{"logical_date": null}'' | jq
              ',
            ]
          volumeMounts:
            - name: airflow-credentials
              mountPath: /airflow-credentials
      volumes:
        - name: airflow-credentials
          secret:
            secretName: airflow-credentials
      restartPolicy: OnFailure
  backoffLimit: 20 # give some time for the Airflow cluster to be available
