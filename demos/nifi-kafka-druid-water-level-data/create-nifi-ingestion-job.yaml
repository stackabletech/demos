---
apiVersion: batch/v1
kind: Job
metadata:
  name: create-nifi-ingestion-job
spec:
  template:
    spec:
      serviceAccountName: demo-serviceaccount
      initContainers:
        - name: wait-for-nifi
          image: oci.stackable.tech/sdp/tools:1.0.0-stackable0.0.0-dev
          command:
            - bash
            - -euo
            - pipefail
            - -c
            - |
              echo 'Waiting for NiFi to be created'
              kubectl wait --for=create pod/nifi-node-default-0 --timeout=30m
              echo 'Waiting for NiFi to be ready'
              kubectl wait --for=condition=Ready pod/nifi-node-default-0 --timeout=30m
      containers:
        - name: create-nifi-ingestion-job
          image: oci.stackable.tech/sdp/testing-tools:0.2.0-stackable0.0.0-dev
          command:
            - bash
            - -euo
            - pipefail
            - -c
            - python -u /tmp/script/script.py
          volumeMounts:
            - name: script
              mountPath: /tmp/script
            - name: nifi-admin-credentials-secret
              mountPath: /nifi-admin-credentials-secret
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      volumes:
        - name: script
          configMap:
            name: create-nifi-ingestion-job-script
        - name: nifi-admin-credentials-secret
          secret:
            secretName: nifi-admin-credentials-secret
      restartPolicy: OnFailure
  backoffLimit: 50
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: create-nifi-ingestion-job-script
data:
  script.py: |
    from nipyapi.canvas import get_root_pg_id, schedule_process_group, list_all_controllers, schedule_controller
    from nipyapi.security import service_login
    import nipyapi
    import os
    import requests
    import urllib3

    # As of 2022-08-29 we cant use "https://nifi:8443" here because <h2>The request contained an invalid host header [<code>nifi:8443</code>] in the request [<code>/nifi-api</code>]. Check for request manipulation or third-party intercept.</h2>
    ENDPOINT = f"https://nifi-node-default-0.nifi-node-default.{os.environ['NAMESPACE']}.svc.cluster.local:8443" # For local testing / developing replace it, afterwards change back to f"https://nifi-node-default-0.nifi-node-default.{os.environ['NAMESPACE']}.svc.cluster.local:8443"
    USERNAME = "admin"
    PASSWORD = open("/nifi-admin-credentials-secret/admin").read()

    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    nipyapi.config.nifi_config.host = f"{ENDPOINT}/nifi-api"
    nipyapi.config.nifi_config.verify_ssl = False

    print(f"Logging in as {USERNAME}")
    service_login(username=USERNAME, password=PASSWORD)
    print("Logged in")

    response = requests.get("https://raw.githubusercontent.com/stackabletech/demos/refs/heads/main/demos/nifi-kafka-druid-water-level-data/IngestWaterLevelsToKafka.json")

    filename = "/tmp/IngestWaterLevelsToKafka.json"
    with open(filename, "wb") as f:
        f.write(response.content)

    pg_id = get_root_pg_id()

    if not nipyapi.config.nifi_config.api_client:
        nipyapi.config.nifi_config.api_client = ApiClient()

    header_params = {}
    header_params['Accept'] = nipyapi.config.nifi_config.api_client.select_header_accept(['application/json'])
    header_params['Content-Type'] = nipyapi.config.nifi_config.api_client.select_header_content_type(['multipart/form-data'])

    nipyapi.config.nifi_config.api_client.call_api('/process-groups/{pg_id}/process-groups/upload', 'POST',
        path_params={'pg_id': pg_id},
        header_params=header_params,
        _return_http_data_only=True,
        post_params=[
            ('id', pg_id),
            ('groupName', 'IngestWaterLevelsToKafka'),
            ('positionX', 100),
            ('positionY', 10),
            ('clientId', nipyapi.nifi.FlowApi().generate_client_id()),
        ],
        files={
            'file': filename
        },
        auth_settings=['tokenAuth'])

    # Scheduling the `Kafka3ConnectionService` fails, if it is started before `StandardRestrictedSSLContextService`, since it depends on it
    # To work around this, we try to schedule the controllers multiple times
    # If `Kafka3ConnectionService` is started before `StandardRestrictedSSLContextService`, scheduling it will fail in the first iteration
    # But it should succeed in the second attempt, since by then `StandardRestrictedSSLContextService` is started
    max_retries = 2
    for _ in range(max_retries):
        controllers = list_all_controllers(pg_id)
        for controller in controllers:
            if controller.component.state != "ENABLED":
                try:
                    schedule_controller(controller, scheduled=True)
                    print(f"Scheduled controller: {controller.component.name}")
                except Exception as e:
                    print(f"Failed to schedule controller {controller.component.name}: {e}")

    schedule_process_group(pg_id, scheduled=True)
