---
apiVersion: batch/v1
kind: Job
metadata:
  name: create-nifi-ingestion-job
spec:
  template:
    spec:
      serviceAccountName: demo-serviceaccount
      initContainers:
        - name: wait-for-nifi
          image: oci.stackable.tech/sdp/tools:1.0.0-stackable0.0.0-dev
          command:
            - bash
            - -euo
            - pipefail
            - -c
            - |
              echo 'Waiting for NiFi to be created'
              kubectl wait --for=create pod/nifi-node-default-0 --timeout=30m
              echo 'Waiting for NiFi to be ready'
              kubectl wait --for=condition=Ready pod/nifi-node-default-0 --timeout=30m
      containers:
        - name: create-nifi-ingestion-job
          image: oci.stackable.tech/sdp/testing-tools:0.2.0-stackable0.0.0-dev
          command:
            - bash
            - -euo
            - pipefail
            - -c
            - python -u /tmp/script/script.py
          volumeMounts:
            - name: script
              mountPath: /tmp/script
            - name: nifi-admin-credentials-secret
              mountPath: /nifi-admin-credentials-secret
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      volumes:
        - name: script
          configMap:
            name: create-nifi-ingestion-job-script
        - name: nifi-admin-credentials-secret
          secret:
            secretName: nifi-admin-credentials-secret
      restartPolicy: OnFailure
  backoffLimit: 50
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: create-nifi-ingestion-job-script
data:
  script.py: |
    from nipyapi.canvas import get_root_pg_id, schedule_process_group, list_all_controllers, schedule_controller
    from nipyapi.security import service_login
    import nipyapi
    import os
    import urllib3

    # As of 2022-08-29 we cant use "https://nifi:8443" here because <h2>The request contained an invalid host header [<code>nifi:8443</code>] in the request [<code>/nifi-api</code>]. Check for request manipulation or third-party intercept.</h2>
    ENDPOINT = f"https://nifi-node-default-0.nifi-node-default.{os.environ['NAMESPACE']}.svc.cluster.local:8443" # For local testing / developing replace it, afterwards change back to f"https://nifi-node-default-0.nifi-node-default.{os.environ['NAMESPACE']}.svc.cluster.local:8443"
    USERNAME = "admin"
    PASSWORD = open("/nifi-admin-credentials-secret/admin").read()

    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    nipyapi.config.nifi_config.host = f"{ENDPOINT}/nifi-api"
    nipyapi.config.nifi_config.verify_ssl = False

    print(f"Logging in as {USERNAME}")
    service_login(username=USERNAME, password=PASSWORD)
    print("Logged in")

    organization = "stackabletech"
    repository = "demos"
    branch = "main"
    version = "main"
    directory = "demos/nifi-kafka-druid-earthquake-data"
    flow_name = "IngestEarthquakesToKafka"

    # Check if the GitHub flow registry client already exists
    flow_registry_clients = nipyapi.nifi.ControllerApi().get_flow_registry_clients().registries

    github_client = None
    for client in flow_registry_clients:
        if client.component.name == "GitHubFlowRegistryClient":
            github_client = client
            print("Found existing GitHub flow registry client")
            break

    if not github_client:
        print("Creating new GitHub flow registry client")
        github_client = nipyapi.nifi.ControllerApi().create_flow_registry_client(
            body={
                "revision": {"version": 0},
                "component": {
                    "name": "GitHubFlowRegistryClient",
                    "type": "org.apache.nifi.github.GitHubFlowRegistryClient",
                    "properties": {
                        "Repository Owner": organization,
                        "Repository Name": repository,
                    },
                    "bundle": {
                        "group": "org.apache.nifi",
                        "artifact": "nifi-github-nar",
                        "version": "2.2.0",
                    },
                },
            }
        )

    pg_id = get_root_pg_id()

    try:
        # Create process group from the file in the Git repo
        nipyapi.nifi.ProcessGroupsApi().create_process_group(
            id=pg_id,
            body={
                "revision": {"version": 0},
                "component": {
                    "position": {"x": 300, "y": 10},
                    "versionControlInformation": {
                        "registryId": github_client.component.id,
                        "flowId": flow_name,
                        "bucketId": directory,
                        "branch": branch,
                        "version": version,
                    },
                },
            },
        )
    except ValueError as e:
        # Ignore, because nipyapi can't handle non-int versions yet
        if "invalid literal for int() with base 10" in str(e):
            print("Ignoring ValueError")
        else:
            raise e

    # Scheduling the `Kafka3ConnectionService` fails, if it is started before `StandardRestrictedSSLContextService`, since it depends on it
    # To work around this, we try to schedule the controllers multiple times
    # If `Kafka3ConnectionService` is started before `StandardRestrictedSSLContextService`, scheduling it will fail in the first iteration
    # But it should succeed in the second attempt, since by then `StandardRestrictedSSLContextService` is started
    max_retries = 2
    for _ in range(max_retries):
        controllers = list_all_controllers(pg_id)
        for controller in controllers:
            if controller.component.state != "ENABLED":
                try:
                    schedule_controller(controller, scheduled=True)
                    print(f"Scheduled controller: {controller.component.name}")
                except Exception as e:
                    print(f"Failed to schedule controller {controller.component.name}: {e}")

    schedule_process_group(pg_id, scheduled=True)
