---
apiVersion: airflow.stackable.tech/v1alpha1
kind: AirflowCluster
metadata:
  name: airflow
spec:
  image:
    productVersion: 3.0.6
    pullPolicy: IfNotPresent
  clusterConfig:
    loadExamples: false
    credentialsSecret: airflow-credentials
    volumes:
      - name: airflow-dags
        configMap:
          name: airflow-dags
    volumeMounts:
      - name: airflow-dags
        mountPath: /stackable/airflow/dags/dbt_trino.py
        subPath: dbt_trino.py
  webservers:
    roleConfig:
      listenerClass: external-stable
    config:
      resources:
        cpu:
          min: "2"
          max: "3"
        memory:
          limit: 3Gi
    roleGroups:
      default:
        replicas: 1
  celeryExecutors:
    roleGroups:
      default:
        replicas: 1
  # kubernetesExecutors:
  #   config: {}
  schedulers:
    roleGroups:
      default:
        replicas: 1
  dagProcessors:
    roleGroups:
      default:
        replicas: 1
  triggerers:
    roleGroups:
      default:
        replicas: 1
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-dags
data:
  dbt_trino.py: |
    from airflow import DAG
    from airflow.providers.cncf.kubernetes.operators.pod import KubernetesPodOperator
    from kubernetes.client import models as k8s

    volume = k8s.V1Volume(
        name="server-tls-mount",
        ephemeral=k8s.V1EphemeralVolumeSource(
            volume_claim_template=k8s.V1PersistentVolumeClaimTemplate(
                metadata=k8s.V1ObjectMeta(
                    annotations={
                        "secrets.stackable.tech/class": "trino-tls",
                        "secrets.stackable.tech/scope": "pod,node"
                    }
                ),
                spec=k8s.V1PersistentVolumeClaimSpec(
                    access_modes=["ReadWriteOnce"],
                    resources=k8s.V1ResourceRequirements(
                        requests={"storage": "1"}
                    ),
                    storage_class_name="secrets.stackable.tech"
                )
            )
        )
    )

    volume_mount = k8s.V1VolumeMount(
      name="server-tls-mount", mount_path="/dbt/trusted"
    )

    pod_security_context = k8s.V1PodSecurityContext(
        fs_group=1000
    )

    with DAG(
        dag_id="run_dbt_check_via_pod_operator",
        schedule=None,
        tags=["Demo", "DBT"],
        catchup=False
    ) as dag:
      run_dbt_check = KubernetesPodOperator(
          image="my-dbt-trino:0.0.1",
          image_pull_policy="IfNotPresent",
          cmds=["/bin/bash", "-x", "-euo", "pipefail", "-c"],
          arguments=["sleep infinity #curl -v -u admin:adminadmin --cacert /dbt/trusted/ca.crt https://trino-coordinator-default-headless.default.svc.cluster.local:8443/v1/info"],
          name="run-dbt-debug",
          task_id="dbt-task",
          get_logs=True,
          volumes=[volume],
          volume_mounts=[volume_mount],
          security_context=pod_security_context,
          startup_timeout_seconds=600
      )
      run_dbt_check
---
apiVersion: v1
kind: Secret
metadata:
  name: airflow-credentials
type: Opaque
stringData:
  adminUser.username: admin
  adminUser.firstname: Airflow
  adminUser.lastname: Admin
  adminUser.email: airflow@airflow.com
  adminUser.password: "adminadmin"
  connections.secretKey: "airflowSecretKey"
  connections.sqlalchemyDatabaseUri: postgresql+psycopg2://airflow:airflow@postgresql-airflow/airflow
  connections.celeryResultBackend: db+postgresql://airflow:airflow@postgresql-airflow/airflow
  connections.celeryBrokerUrl: redis://:redis@redis-airflow-master:6379/0
