---
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-connect-log-config
data:
  log4j2.properties: |-
    appenders = CONSOLE

    appender.CONSOLE.type = Console
    appender.CONSOLE.name = CONSOLE
    appender.CONSOLE.target = SYSTEM_ERR
    appender.CONSOLE.layout.type = PatternLayout
    appender.CONSOLE.layout.pattern = %d{ISO8601} %p [%t] %c - %m%n
    appender.CONSOLE.filter.threshold.type = ThresholdFilter
    appender.CONSOLE.filter.threshold.level = DEBUG

    rootLogger.level=INFO
    rootLogger.appenderRefs = CONSOLE
    rootLogger.appenderRef.CONSOLE.ref = CONSOLE

---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkConnectServer
metadata:
  name: spark-connect
  labels:
    stackable.tech/vendor: Stackable
spec:
  image:
    # Using an image that includes scikit-learn (among other things)
    # because this package needs to be available on the executors.
    custom: oci.stackable.tech/stackable/spark-connect-client:3.5.5-stackable0.0.0-dev
    productVersion: 3.5.5
    pullPolicy: IfNotPresent
  args:
  server:
    configOverrides:
      spark-defaults.conf:
        spark.jars.ivy: /tmp/ivy2
        spark.driver.memory: "2g"
    podOverrides:
      spec:
        containers:
          - name: spark
            env:
              - name: HADOOP_CONF_DIR
                value: /hdfs-config
            volumeMounts:
              - name: hdfs-discovery-configmap
                mountPath: /hdfs-config
        volumes:
          - name: hdfs-discovery-configmap
            configMap:
              name: hdfs
    config:
      resources:
        memory:
          limit: "2Gi"
      logging:
        enableVectorAgent: false
        containers:
          spark:
            custom:
              configMap: spark-connect-log-config
  executor:
    configOverrides:
      spark-defaults.conf:
        spark.executor.instances: "4"
        spark.executor.memory: "3g"
        spark.executor.memoryOverhead: "0m"
    config:
      resources:
        memory:
          limit: "3Gi"
      logging:
        enableVectorAgent: false
        containers:
          spark:
            custom:
              configMap: spark-connect-log-config
