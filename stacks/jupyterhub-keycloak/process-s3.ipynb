{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f37284",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -al /usr/local/spark/jars | grep spark-core\n",
    "! python3 -V\n",
    "! java --version\n",
    "! pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606363ba-0c97-4156-af1c-c8ad54745cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "NAMESPACE = os.environ.get(\"NAMESPACE\", \"default\")\n",
    "POD_NAME = os.environ.get(\"HOSTNAME\", f\"jupyter-{os.environ.get('USER', 'default')}-{NAMESPACE}\")\n",
    "\n",
    "# works with python-3.11 notebook image\n",
    "#EXECUTOR_IMAGE = \"oci.stackable.tech/sdp/spark-k8s:3.5.0-stackable24.3.0\" \n",
    "\n",
    "# jars differ in size, 17.0.12 vs. 17.0.13, 3.11.10 vs. 3.11.9\n",
    "#SerializableBuffer conflict\n",
    "#EXECUTOR_IMAGE = \"oci.stackable.tech/sdp/spark-k8s:3.5.2-stackable24.11.1\" \n",
    "\n",
    "# java, jars match\n",
    "#Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions. \n",
    "#EXECUTOR_IMAGE = \"apache/spark:3.5.2-java17-python3\" \n",
    "\n",
    "# java, jars match\n",
    "#Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions. \n",
    "#EXECUTOR_IMAGE = \"spark:3.5.2-scala2.12-java17-python3-ubuntu\" \n",
    "\n",
    "#Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.\n",
    "#EXECUTOR_IMAGE = \"bitnami/spark:3.5.2\"\n",
    "\n",
    "# custom image with python 3.11 - works!\n",
    "# based off: spark:3.5.2-scala2.12-java17-ubuntu\n",
    "# see: \n",
    "EXECUTOR_IMAGE = \"spark:3.5.2-python311\" \n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(f'k8s://https://{os.environ[\"KUBERNETES_SERVICE_HOST\"]}:{os.environ[\"KUBERNETES_SERVICE_PORT\"]}')\n",
    "    .appName(\"process-s3-data\")\n",
    "    .config(\"spark.kubernetes.container.image\", EXECUTOR_IMAGE)\n",
    "    .config(\"spark.kubernetes.container.image.pullPolicy\", \"IfNotPresent\")\n",
    "    .config(\"spark.kubernetes.namespace\", NAMESPACE)\n",
    "    .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"spark\")\n",
    "    .config(\"spark.kubernetes.authenticate.executor.serviceAccountName\", \"spark\")\n",
    "    .config(\"spark.driver.port\", \"2222\")\n",
    "    .config(\"spark.driver.blockManager.port\", \"7777\")\n",
    "    .config(\"spark.executor.instances\", \"1\")\n",
    "    .config(\"spark.executor.memory\", \"1g\")\n",
    "    .config(\"spark.executor.cores\", \"1\")\n",
    "    # bitnami. See https://github.com/bitnami/containers/issues/52698#issuecomment-2275913474\n",
    "    #.config(\"spark.executorEnv.LD_PRELOAD\", \"/opt/bitnami/common/lib/libnss_wrapper.so\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000/\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"adminadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-client-api:3.3.4,org.apache.hadoop:hadoop-client-runtime:3.3.4,org.apache.hadoop:hadoop-aws:3.3.4,org.apache.hadoop:hadoop-common:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.162\")\n",
    "    .config(\"spark.submit.deployMode\", \"client\")\n",
    "    .config(\"spark.kubernetes.driver.pod.name\", POD_NAME)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1ab91-ab2e-49b0-a72f-164915e4ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"a\", 1), (\"b\", 2)], [\"col1\", \"col2\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8479cb-f216-4a8f-b9db-6da17ffebaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual check via pyarrow.fs\n",
    "import pyarrow.fs as fs\n",
    "s3 = fs.S3FileSystem(endpoint_override=\"http://minio:9000/\", access_key=\"admin\", secret_key=\"adminadmin\", scheme=\"http\")\n",
    "files = s3.get_file_info(fs.FileSelector(\"demo/gas-sensor/raw/\", recursive=True))\n",
    "for f in files:\n",
    "    print(\"Found file:\", f.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"s3a://demo/gas-sensor/raw/\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35861943-7586-434f-a03d-31ebf03b59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"s3a://demo/gas-sensor/rewritten/\", mode=\"overwrite\")\n",
    "df.write.parquet(\"s3a://demo/gas-sensor/parquet/\", mode=\"overwrite\")\n",
    "\n",
    "df2 = spark.read.parquet(\"s3a://demo/gas-sensor/parquet/\", header = True)\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319fa38-96de-4c8a-96e0-8e47ef5a7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions\n",
    "\n",
    "df2 = df2.withColumn(\"hour\", (functions.floor(df2.timesecs / 60) + 1))\n",
    "\n",
    "dfs = df2.select(\n",
    "    df2.hour,\n",
    "    df2.humidity,\n",
    "    df2.temperature,\n",
    "    df2.flowrate\n",
    ").groupby(\"hour\").agg(\n",
    "    functions.round(functions.avg('humidity'), 2).alias('humidity'),\n",
    "    functions.round(functions.avg('temperature'), 2).alias('temperature'),\n",
    "    functions.round(functions.avg('flowrate'), 2).alias('flowrate')\n",
    ").orderBy(\"hour\")\n",
    "\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.write.parquet(\"s3a://demo/gas-sensor/agg/\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
